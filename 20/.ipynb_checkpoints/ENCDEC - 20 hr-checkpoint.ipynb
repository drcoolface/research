{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bef5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671f827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../finaldata.csv', sep=',').set_index('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205b7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60843e5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T2M</th>\n",
       "      <th>QV2M</th>\n",
       "      <th>PRECTOTCORR</th>\n",
       "      <th>WS10M</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-02 00:00:00</th>\n",
       "      <td>12.12</td>\n",
       "      <td>5.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-02 01:00:00</th>\n",
       "      <td>11.80</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-02 02:00:00</th>\n",
       "      <td>11.32</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-02 03:00:00</th>\n",
       "      <td>11.03</td>\n",
       "      <td>5.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-02 04:00:00</th>\n",
       "      <td>10.92</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-15 01:00:00</th>\n",
       "      <td>12.45</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>0.966848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-15 02:00:00</th>\n",
       "      <td>12.25</td>\n",
       "      <td>7.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>0.966848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-15 03:00:00</th>\n",
       "      <td>11.83</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>0.966848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-15 04:00:00</th>\n",
       "      <td>11.60</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>0.966848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-15 05:00:00</th>\n",
       "      <td>11.69</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>0.966848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156630 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       T2M  QV2M  PRECTOTCORR  WS10M  Hour_sin  Hour_cos  \\\n",
       "Date                                                                       \n",
       "2005-01-02 00:00:00  12.12  5.68          0.0   1.14  0.000000  1.000000   \n",
       "2005-01-02 01:00:00  11.80  5.62          0.0   1.26  0.258819  0.965926   \n",
       "2005-01-02 02:00:00  11.32  5.55          0.0   1.40  0.500000  0.866025   \n",
       "2005-01-02 03:00:00  11.03  5.43          0.0   1.53  0.707107  0.707107   \n",
       "2005-01-02 04:00:00  10.92  5.31          0.0   1.65  0.866025  0.500000   \n",
       "...                    ...   ...          ...    ...       ...       ...   \n",
       "2022-11-15 01:00:00  12.45  7.45          0.0   0.76  0.258819  0.965926   \n",
       "2022-11-15 02:00:00  12.25  7.32          0.0   0.96  0.500000  0.866025   \n",
       "2022-11-15 03:00:00  11.83  7.20          0.0   1.06  0.707107  0.707107   \n",
       "2022-11-15 04:00:00  11.60  7.08          0.0   1.13  0.866025  0.500000   \n",
       "2022-11-15 05:00:00  11.69  6.96          0.0   1.22  0.965926  0.258819   \n",
       "\n",
       "                      Day_sin   Day_cos  \n",
       "Date                                     \n",
       "2005-01-02 00:00:00  0.034422  0.999407  \n",
       "2005-01-02 01:00:00  0.034422  0.999407  \n",
       "2005-01-02 02:00:00  0.034422  0.999407  \n",
       "2005-01-02 03:00:00  0.034422  0.999407  \n",
       "2005-01-02 04:00:00  0.034422  0.999407  \n",
       "...                       ...       ...  \n",
       "2022-11-15 01:00:00  0.255353  0.966848  \n",
       "2022-11-15 02:00:00  0.255353  0.966848  \n",
       "2022-11-15 03:00:00  0.255353  0.966848  \n",
       "2022-11-15 04:00:00  0.255353  0.966848  \n",
       "2022-11-15 05:00:00  0.255353  0.966848  \n",
       "\n",
       "[156630 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a74a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_out=20\n",
    "n_steps_in= 24\n",
    "n_features = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c85652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(df, n_steps_in, n_steps_out):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np)):\n",
    " # find the end of this pattern\n",
    "         end_ix = i + n_steps_in\n",
    "         out_end_ix = end_ix + n_steps_out\n",
    " # check if we are beyond the dataset\n",
    "         if out_end_ix > len(df_as_np):\n",
    "             break\n",
    " # gather input and output parts of the pattern\n",
    "         seq_x, seq_y = df_as_np[i:end_ix, :], df_as_np[end_ix:out_end_ix, :2]\n",
    "         X.append(seq_x)\n",
    "         y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9779cc01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156587, 24, 8), (156587, 20, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = split_sequences(b, n_steps_out=20,\n",
    "n_steps_in= 24)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70625c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given X = [ 1.21200000e+01  5.68000000e+00  0.00000000e+00  1.14000000e+00\n",
      "  0.00000000e+00  1.00000000e+00  3.44216116e-02  9.99407401e-01\n",
      "  1.18000000e+01  5.62000000e+00  0.00000000e+00  1.26000000e+00\n",
      "  2.58819045e-01  9.65925826e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.13200000e+01  5.55000000e+00  0.00000000e+00  1.40000000e+00\n",
      "  5.00000000e-01  8.66025404e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.10300000e+01  5.43000000e+00  0.00000000e+00  1.53000000e+00\n",
      "  7.07106781e-01  7.07106781e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.09200000e+01  5.31000000e+00  0.00000000e+00  1.65000000e+00\n",
      "  8.66025404e-01  5.00000000e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.10000000e+01  5.25000000e+00  0.00000000e+00  1.69000000e+00\n",
      "  9.65925826e-01  2.58819045e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.10500000e+01  5.19000000e+00  0.00000000e+00  1.70000000e+00\n",
      "  1.00000000e+00  6.12323400e-17  3.44216116e-02  9.99407401e-01\n",
      "  1.14800000e+01  5.31000000e+00  0.00000000e+00  1.66000000e+00\n",
      "  9.65925826e-01 -2.58819045e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.31800000e+01  6.53000000e+00  0.00000000e+00  1.45000000e+00\n",
      "  8.66025404e-01 -5.00000000e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.56800000e+01  6.16000000e+00  0.00000000e+00  1.57000000e+00\n",
      "  7.07106781e-01 -7.07106781e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.76200000e+01  5.80000000e+00  0.00000000e+00  2.09000000e+00\n",
      "  5.00000000e-01 -8.66025404e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.90400000e+01  6.10000000e+00  0.00000000e+00  2.59000000e+00\n",
      "  2.58819045e-01 -9.65925826e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.98900000e+01  6.35000000e+00  0.00000000e+00  3.08000000e+00\n",
      "  1.22464680e-16 -1.00000000e+00  3.44216116e-02  9.99407401e-01\n",
      "  2.01300000e+01  6.59000000e+00  0.00000000e+00  3.43000000e+00\n",
      " -2.58819045e-01 -9.65925826e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.99000000e+01  6.71000000e+00  0.00000000e+00  3.59000000e+00\n",
      " -5.00000000e-01 -8.66025404e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.89800000e+01  6.77000000e+00  0.00000000e+00  3.51000000e+00\n",
      " -7.07106781e-01 -7.07106781e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.67500000e+01  7.57000000e+00  0.00000000e+00  2.48000000e+00\n",
      " -8.66025404e-01 -5.00000000e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.28000000e+01  7.14000000e+00  0.00000000e+00  1.73000000e+00\n",
      " -9.65925826e-01 -2.58819045e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.18300000e+01  6.53000000e+00  0.00000000e+00  1.16000000e+00\n",
      " -1.00000000e+00 -1.83697020e-16  3.44216116e-02  9.99407401e-01\n",
      "  1.13600000e+01  6.23000000e+00  0.00000000e+00  1.20000000e+00\n",
      " -9.65925826e-01  2.58819045e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.10500000e+01  5.92000000e+00  0.00000000e+00  1.53000000e+00\n",
      " -8.66025404e-01  5.00000000e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.09500000e+01  5.62000000e+00  0.00000000e+00  1.69000000e+00\n",
      " -7.07106781e-01  7.07106781e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.07300000e+01  5.37000000e+00  0.00000000e+00  1.72000000e+00\n",
      " -5.00000000e-01  8.66025404e-01  3.44216116e-02  9.99407401e-01\n",
      "  1.07600000e+01  5.13000000e+00  0.00000000e+00  1.69000000e+00\n",
      " -2.58819045e-01  9.65925826e-01  3.44216116e-02  9.99407401e-01] \n",
      "\n",
      "we predict [10.7   4.88 10.64  4.7  10.68  4.46 10.52  4.21 10.06  4.03  9.93  3.85\n",
      "  9.69  3.66 10.25  3.72 13.55  6.04 17.64  4.76 19.88  4.76 20.98  4.64\n",
      " 21.4   4.52 21.34  4.52 20.76  4.58 19.45  4.94 16.74  6.47 12.87  6.04\n",
      " 11.72  5.62 11.38  5.49]\n"
     ]
    }
   ],
   "source": [
    "print(f'Given X = {X[0].flatten()} \\n')\n",
    "print(f'we predict {y[0].flatten()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d84637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135000, 24, 8),\n",
       " (135000, 20, 2),\n",
       " (15000, 24, 8),\n",
       " (15000, 20, 2),\n",
       " (6587, 24, 8),\n",
       " (6587, 20, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = X[:135000], y[:135000]\n",
    "X_val, y_val = X[135000:150000], y[135000:150000]\n",
    "X_test, y_test = X[150000:], y[150000:]\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "467e44d1",
   "metadata": {},
   "source": [
    "## Model 1 : GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b71be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 64)                14208     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 20, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 20, 32)            9408      \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 20, 2)            66        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,682\n",
      "Trainable params: 23,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_enc_gru = Sequential()\n",
    "model_enc_gru.add(GRU(64, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model_enc_gru.add(RepeatVector(n_steps_out))\n",
    "model_enc_gru.add(GRU(32, activation='relu', return_sequences=True))\n",
    "model_enc_gru.add(TimeDistributed(Dense(2)))\n",
    "model_enc_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0524e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_gru = ModelCheckpoint('model_gru', save_best_only=True, monitor='val_loss')\n",
    "model_enc_gru.compile(loss='mean_absolute_percentage_error', optimizer=Adam(learning_rate=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da188c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 17.5591INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 103s 24ms/step - loss: 17.5591 - val_loss: 14.7034\n",
      "Epoch 2/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 11.5259INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 88s 21ms/step - loss: 11.5251 - val_loss: 12.7964\n",
      "Epoch 3/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 9.1610INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 99s 23ms/step - loss: 9.1610 - val_loss: 12.5117\n",
      "Epoch 4/200\n",
      "4219/4219 [==============================] - 90s 21ms/step - loss: 8.2933 - val_loss: 12.7614\n",
      "Epoch 5/200\n",
      "4219/4219 [==============================] - 94s 22ms/step - loss: 7.8115 - val_loss: 13.1032\n",
      "Epoch 6/200\n",
      "4219/4219 [==============================] - 92s 22ms/step - loss: 7.5463 - val_loss: 12.9289\n",
      "Epoch 7/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 7.3555INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 101s 24ms/step - loss: 7.3555 - val_loss: 12.5087\n",
      "Epoch 8/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 7.1978INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 101s 24ms/step - loss: 7.1978 - val_loss: 12.2475\n",
      "Epoch 9/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 7.0558INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 88s 21ms/step - loss: 7.0558 - val_loss: 11.6972\n",
      "Epoch 10/200\n",
      "4218/4219 [============================>.] - ETA: 0s - loss: 6.9158INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 96s 23ms/step - loss: 6.9155 - val_loss: 11.1240\n",
      "Epoch 11/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 6.7907INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 103s 24ms/step - loss: 6.7907 - val_loss: 10.5666\n",
      "Epoch 12/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 6.6680INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 93s 22ms/step - loss: 6.6680 - val_loss: 10.0833\n",
      "Epoch 13/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 6.5603INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 110s 26ms/step - loss: 6.5602 - val_loss: 9.7121\n",
      "Epoch 14/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 6.4704INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 93s 22ms/step - loss: 6.4703 - val_loss: 9.3880\n",
      "Epoch 15/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 6.3962INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 101s 24ms/step - loss: 6.3962 - val_loss: 9.0945\n",
      "Epoch 16/200\n",
      "4218/4219 [============================>.] - ETA: 0s - loss: 6.3283INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 94s 22ms/step - loss: 6.3279 - val_loss: 8.8773\n",
      "Epoch 17/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 6.2705INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 91s 22ms/step - loss: 6.2704 - val_loss: 8.6816\n",
      "Epoch 18/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 6.2203INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 101s 24ms/step - loss: 6.2202 - val_loss: 8.4578\n",
      "Epoch 19/200\n",
      "4218/4219 [============================>.] - ETA: 0s - loss: 6.1739INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 101s 24ms/step - loss: 6.1735 - val_loss: 8.3029\n",
      "Epoch 20/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 6.1339INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 88s 21ms/step - loss: 6.1338 - val_loss: 8.1176\n",
      "Epoch 21/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 6.0935INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 108s 26ms/step - loss: 6.0935 - val_loss: 7.9552\n",
      "Epoch 22/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 6.0617INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 99s 23ms/step - loss: 6.0617 - val_loss: 7.7906\n",
      "Epoch 23/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 6.0262INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 101s 24ms/step - loss: 6.0262 - val_loss: 7.6502\n",
      "Epoch 24/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 5.9977INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 107s 25ms/step - loss: 5.9977 - val_loss: 7.5248\n",
      "Epoch 25/200\n",
      "4218/4219 [============================>.] - ETA: 0s - loss: 5.9678INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 94s 22ms/step - loss: 5.9675 - val_loss: 7.4409\n",
      "Epoch 26/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 5.9387INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 106s 25ms/step - loss: 5.9387 - val_loss: 7.3364\n",
      "Epoch 27/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 5.9124INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 96s 23ms/step - loss: 5.9124 - val_loss: 7.2612\n",
      "Epoch 28/200\n",
      "4218/4219 [============================>.] - ETA: 0s - loss: 5.8876INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 93s 22ms/step - loss: 5.8873 - val_loss: 7.1894\n",
      "Epoch 29/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 5.8644INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 95s 22ms/step - loss: 5.8644 - val_loss: 7.1147\n",
      "Epoch 30/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 5.8393INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 94s 22ms/step - loss: 5.8393 - val_loss: 7.0590\n",
      "Epoch 31/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 5.8223INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 102s 24ms/step - loss: 5.8223 - val_loss: 6.9840\n",
      "Epoch 32/200\n",
      "4217/4219 [============================>.] - ETA: 0s - loss: 5.7977INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 99s 23ms/step - loss: 5.7977 - val_loss: 6.9479\n",
      "Epoch 33/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 5.7832INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 98s 23ms/step - loss: 5.7832 - val_loss: 6.8561\n",
      "Epoch 34/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 5.7583INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 96s 23ms/step - loss: 5.7583 - val_loss: 6.8317\n",
      "Epoch 35/200\n",
      "4219/4219 [==============================] - ETA: 0s - loss: 5.7481INFO:tensorflow:Assets written to: model_gru/assets\n",
      "4219/4219 [==============================] - 98s 23ms/step - loss: 5.7481 - val_loss: 6.7334\n",
      "Epoch 36/200\n",
      "1623/4219 [==========>...................] - ETA: 57s - loss: 5.5368"
     ]
    }
   ],
   "source": [
    "history = model_enc_gru.fit(X_train, y_train, batch_size = 32, shuffle=False, validation_data=(X_val, y_val), epochs=200, callbacks=[cp_gru,EarlyStopping(monitor='val_loss', patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('MAPE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('gru.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bd28b",
   "metadata": {},
   "source": [
    "MODEL LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebbac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enc_LSTM = Sequential()\n",
    "model_enc_LSTM.add(LSTM(64, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model_enc_LSTM.add(RepeatVector(n_steps_out))\n",
    "model_enc_LSTM.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "model_enc_LSTM.add(TimeDistributed(Dense(2)))\n",
    "model_enc_LSTM.summary()\n",
    "\n",
    "cp_lstm = ModelCheckpoint('model_lstm', save_best_only=True, monitor='val_loss')\n",
    "model_enc_LSTM.compile(loss='mean_absolute_percentage_error', optimizer=Adam(learning_rate=0.0001))\n",
    "history2 = model_enc_LSTM.fit(X_train, y_train, batch_size = 32, shuffle=False, validation_data=(X_val, y_val), epochs=200, callbacks=[cp_lstm,EarlyStopping(monitor='val_loss', patience=20)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('MAPE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('lstm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65759301",
   "metadata": {},
   "source": [
    "MODEL BIDIRECTIONAL LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0c2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enc_biLSTM = Sequential()\n",
    "model_enc_biLSTM.add(Bidirectional(LSTM(64, activation='relu', input_shape=(n_steps_in, n_features))))\n",
    "model_enc_biLSTM.add(RepeatVector(n_steps_out))\n",
    "\n",
    "model_enc_biLSTM.add(Bidirectional(LSTM(32, activation='relu', return_sequences=True)))\n",
    "model_enc_biLSTM.add(TimeDistributed(Dense(2)))\n",
    "model_enc_biLSTM.build(input_shape=(None,n_steps_in, n_features))\n",
    "model_enc_biLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d000580",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cp_bilstm = ModelCheckpoint('model_bilstm', save_best_only=True, monitor='val_loss')\n",
    "model_enc_biLSTM.compile(loss='mean_absolute_percentage_error', optimizer=Adam(learning_rate=0.0001))\n",
    "history3 = model_enc_biLSTM.fit(X_train, y_train, batch_size = 32, shuffle=False, validation_data=(X_val, y_val), epochs=200, callbacks=[cp_bilstm,EarlyStopping(monitor='val_loss', patience=20)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24070952",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('MAPE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('bilstm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13abd477",
   "metadata": {},
   "source": [
    "MODEL BIDIRECTIONAL GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2cd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enc_bigru = Sequential()\n",
    "model_enc_bigru.add(Bidirectional(GRU(64, activation='relu', input_shape=(n_steps_in, n_features))))\n",
    "model_enc_bigru.add(RepeatVector(n_steps_out))\n",
    "\n",
    "model_enc_bigru.add(Bidirectional(GRU(32, activation='relu', return_sequences=True)))\n",
    "model_enc_bigru.add(TimeDistributed(Dense(2)))\n",
    "model_enc_bigru.build(input_shape=(None,n_steps_in, n_features))\n",
    "model_enc_bigru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77380b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cp_bigru = ModelCheckpoint('model_bigru', save_best_only=True, monitor='val_loss')\n",
    "model_enc_bigru.compile(loss='mean_absolute_percentage_error', optimizer=Adam(learning_rate=0.0001))\n",
    "history4 = model_enc_bigru.fit(X_train, y_train, batch_size = 32, shuffle=False, validation_data=(X_val, y_val), epochs=150, callbacks=[cp_bigru,EarlyStopping(monitor='val_loss', patience=50)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history4.history['loss'])\n",
    "plt.plot(history4.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('MAPE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('bigru.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
